// IMPORTANT
## Cloud Run 用の Prometheus サイドカーを使用する

https://cloud.google.com/stackdriver/docs/managed-prometheus/cloudrun-sidecar?hl=ja

Cloud Run 用の Managed Service for Prometheus サイドカーは、Cloud Run サービスで Prometheus スタイルのモニタリングを行うために `Google が推奨する`方法。

### Cloud Run サービスにサイドカーを追加する（デフォルト構成）

デフォルトの RunMonitoring 構成でサイドカーを使用するには、既存の Cloud Run 構成を変更してサイドカーを追加する必要がある。サイドカーを追加するには、次の操作を行う。

- コンテナの起動とシャットダウンの順序を指定するコンテナ依存関係アノテーションを追加する。次の例では、collector という名前のサイドカー コンテナが、app という名前のアプリケーション コンテナの後に起動し、その後シャットダウンする
- コレクタのコンテナを作成する。次の例では collector という名前にしている。

```yml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  annotations:
    run.googleapis.com/launch-stage: ALPHA
    run.googleapis.com/cpu-throttling: 'false'
  name: my-cloud-run-service
spec:
  template:
    metadata∫:
      annotations:
        run.googleapis.com/execution-environment: gen2
+       run.googleapis.com/container-dependencies: '{"collector":["app"]}'
    spec:
      containers:
      - image: "REGION-docker.pkg.dev/PROJECT_ID/run-gmp/sample-app"
        name: app
        startupProbe:
          httpGet:
            path: /startup
            port: 8000
        livenessProbe:
          httpGet:
            path: /liveness
            port: 8000
        ports:
        - containerPort: 8000
+     - image: "us-docker.pkg.dev/cloud-ops-agents-artifacts/cloud-run-gmp-sidecar/cloud-run-gmp-sidecar:1.1.1"
+       name: collector∫
```

`デフォルト構成を使用する場合`、上記のCloud Run サービスにサイドカーを追加する以外の追加設定は必要ない。
これさえ設定すれば、以下の内容でスクレイピングが実施される。

```yml
apiVersion: monitoring.googleapis.com/v1beta
kind: RunMonitoring
metadata:
  name: run-gmp-sidecar
spec:
  endpoints:
  - port: 8080
    path: /metrics
    interval: 30s
```

### Cloud Run サービスにサイドカーを追加する（カスタム構成）

デフォルトの構成では不十分な場合は、Cloud Run サービスの RunMonitoring 構成を作成できる。たとえば、次のような構成を作成できる。

```yml
apiVersion: monitoring.googleapis.com/v1beta
kind: RunMonitoring
metadata:
  name: my-custom-cloud-run-job
spec:
  endpoints:
  - port: 8080
    path: /metrics
    interval: 10s
    metricRelabeling:
    - action: replace
      sourceLabels:
      - __address__
      targetLabel: label_key
      replacement: label_value
  targetLabels:
    metadata:
    - service
    - revision
```

カスタム RunMonitoring 構成を使用する場合は、次の追加構成を行う必要がある。

- Secret Manager API を有効にして、Cloud Run サービス アカウントに Secret Manager のロールを付与する
- カスタム構成をシークレットとして保存
- Cloud Run サービスにサイドカーを追加

## Google Cloud Managed Service for Prometheus

https://cloud.google.com/stackdriver/docs/managed-prometheus?hl=ja

- Google Cloud Managed Service for Prometheus は、Google Cloud の Prometheus 指標向けのフルマネージド マルチクラウド ソリューション
- Prometheus を大規模に手動で管理、運用することなく、Prometheus を使用してワークロードをモニタリングし、アラートを送信できるようになる
- Managed Service for Prometheus は、Prometheus エクスポータから指標を収集し、`PromQL` を使用してグローバルなデータクエリを可能にする
- 既存の Grafana ダッシュボード（PromQL ベースのアラート）とワークフローを引き続き使用できる
- り、Kubernetes、VM ワークロード、Cloud Run のサーバレス ワークロードをモニタリングできる

### データ収集

データ収集は、`マネージド コレクタ`、`セルフデプロイ コレクタ`、`OpenTelemetry Collector`、または `Ops エージェント`によって処理される。（Managed Service for Prometheus では、マネージド データ収集、セルフデプロイのデータ収集、OpenTelemetry Collector または Ops エージェントの 4 つのいずれかのモードで使用できる）

これらのコレクタは、ローカル エクスポータをスクレイピングして、収集したデータを Monarch に転送する。

- Managed Service for Prometheus 
  - Kubernetes 環境でマネージド モードでデータを収集するオペレーターを提供
  - データの収集はマネージド モードで行うことをおすすめ
  - マネージド収集は、GKE と GKE 以外の Kubernetes 環境でサポートされている
- セルフデプロイ収集
  - Prometheus 環境を通常どおりユーザー自身で管理する
- ⭐️OpenTelemetry Collector 
  - Prometheus エクスポータをスクレイピングし、Managed Service for Prometheus にデータを送信するために使用できる
  - `Prometheus 指標または OTLP 指標を書き込む Cloud Run サービスがある場合は、サイドカーと Managed Service for Prometheus を使用して、指標を Cloud Monitoring に送信できる`
    - Cloud Run から Prometheus 指標を収集するには、Prometheus サイドカーを使用する！

## Google Cloud Managed Service for Prometheusとは？

GMP（Google Cloud ）は、Prometheusのマネージドサービス。

Cloud Monitoringと統合されており、Cloud Monitoring上でメトリクスを表示することが可能。

https://speakerdeck.com/kojake_300/google-cloud-managed-service-for-prometheusteprismametorikusuwoke-shi-hua-sitemita?slide=7

## PromQLとは？

PromQL は、Prometheus で収集された指標に対する強力で柔軟なクエリ言語。

## Google CloudとPrometheusの繋ぎ込み

PrismaのメトリクスをPrometheusで取得し、Google Cloud Monitoringでビジュアライズしたい。Prismaのコネクション数の変遷を把握したい。負荷試験のときとかに

## Database Metrics with Prisma, Prometheus & Grafana

⭐️PrismaとPrometheusとGoogle Cloud MonitoringやGrafanaを連携させたいときにとても参考になりそう。

https://www.prisma.io/blog/metrics-tutorial-prisma-pmoldgq10kz

メトリクスはアプリケーションで直接分析できるほか、PrometheusやStatsDのような外部のモニタリングシステムや時系列データベースに送信することもできる。

これにより、以下のメリットを得られる。

- 可視化とダッシュボードによるリアルタイムのパフォーマンス監視
- 履歴データの照会と分析
- 障害やパフォーマンス低下に対する正確で自動化されたアラート

### Prometheusをアプリに組み込む

Prometheusは、特定のエンドポイントから定期的にデータを要求することでメトリクスを収集する。
http://localhost:4000/metrics エンドポイントからメトリクス・データをスクレイピングするように Prometheus を構成する。

Prometheusの設定ファイルを作る。

```yml
# prometheus/prometheus.yml

scrape_configs:
  - job_name: 'prometheus'
    scrape_interval: 1s

    static_configs:
      - targets: ['host.docker.internal:4000']
        labels:
          service: 'prisma-metrics'
          group: 'production'
```

- job_name は、特定の構成からのメトリクスを識別するために使用されるメタデータ
- scrape_interval は、Prometheus がメトリクス・エンドポイントをスクレイピングする間隔
- targetsは、スクレイピングするエンドポイントのリストです。デフォルトでは、Prometheusは/metricsエンドポイントをスクレイピングします。そのため、明示的に指定する必要はありません

設定ファイルができたら、`Prometheus（Prometheus インスタンス）を動作させる`必要がある。

### Add a Prometheus data source to Grafana

Grafanaにデータソースを追加する必要がある。データソースとは、Grafanaがメトリクスデータを取得するためにクエリできる外部システムのこと。今回の場合、データソースはPrometheusになる。

## 10分で理解する Prometheus

https://qiita.com/Chanmoro/items/ac0eb1bf93760566b338

- Prometheus とは
  - SoundCloud が中心になって開発しているプル型のリソース監視ソフトウェア
- Prometheus でできること
  - 監視対象が動的に変更されるようなスケーラブルな環境のリソース監視を意識した設計になっている
    - 監視対象のサーバーから情報を取得 & 保管
    - 保管済みデータに対して集計クエリを発行できる
    - しきい値を超えた場合のアラート (メール、Slack)
    - 柔軟なアラート設定 (同じエラーはまとめて通知とかの設定ができる)
- 登場人物
  - exporter
    - 監視対象サーバー上で動かすプログラム
テキスト形式でリソース情報を公開するWeb API のようなもの
    - 監視対象のリソース毎に exporter が用意されている
  - prometheus
    - 監視サーバーのプログラム
定期的に全ての exporter をポーリングしてリソース情報を収集する
    - 監視したデータは prometheus 内の DB に保持される

## OpenTelemetry tracingの項目

Cloud Traceの画面とかを見るときに役立つ。

https://www.prisma.io/docs/orm/prisma-client/observability-and-logging/opentelemetry-tracing

- prisma:client:operation： Prisma Clientからデータベースへの、そしてデータベースからPrisma Clientへの操作全体を表します。Prisma Clientが呼び出したモデルやメソッドなどの詳細が含まれます。Prisma操作に応じて、次のスパンの1つ以上が含まれます：
  - `prisma:client:connect`： Prisma Clientがデータベースに接続するまでの時間を表します。
  - prisma:client:serialize： Prisma Clientの操作を検証し、クエリエンジン用のクエリに変換するのにかかる時間を表します。
  - prisma:engine： クエリエンジンでのクエリにかかる時間を表します。
    - `prisma:engine:connection`： Prisma Clientがデータベースconnectionを取得するのにかかる時間を表します。
    - prisma:engine:db_query： データベースに対して実行されたデータベースクエリを表します。タグ内のクエリと、クエリの実行にかかった時間が含まれます。
    - prisma:engine:serialize： データベースクエリの結果をPrisma Clientの結果に変換するのにかかった時間を表します。

## Prisma: Metrics

https://www.prisma.io/docs/orm/prisma-client/observability-and-logging/metrics

メトリクスを JSON または Prometheus 形式でエクスポートしてコンソール・ログで表示したり、StatsD や Prometheus などの外部メトリクス・システムに統合したりできる。外部のメトリクス・システムに統合した場合は、メトリクス・データを時系列で表示できる。例えば、メトリクスを使用して、アプリケーションのアイドル接続数とアクティブ接続数がどのように変化するかを診断できる。

以下のようにメトリクスを取得できる。

```ts
const metrics = await prisma.$metrics.json()
console.log(metrics)
```

例えば、MetricsControllerみたいなの作って、10秒ごとにそこを叩くとかしたら、いい感じにGoogle Cloud上とかにPrismaのメトリクスをvisualizeできる。

### Prometheusメトリクス・システムでPrismaクライアント・メトリクスを使用する

ほとんどの場合、Prometheusはメトリクスを取得するためにエンドポイントをスクレイピングする必要があります。次の例では、Express.jsを使用してデータを送信する方法を示します。

```ts
import { PrismaClient } from '@prisma/client'
import express, { Request, Response } from 'express'

const app = express()
const port = 4000
const prisma = new PrismaClient()

app.get('/metrics', async (_req, res: Response) => {
  const metrics = await prisma.$metrics.prometheus()
  res.end(metrics)
})

app.listen(port, () => {
  console.log(`Example app listening on port ${port}`)
})
```

参考: https://speakerdeck.com/kojake_300/google-cloud-managed-service-for-prometheusteprismametorikusuwoke-shi-hua-sitemita?slide=18
参考: https://www.prisma.io/blog/metrics-tutorial-prisma-pmoldgq10kz

// IMPORTANT
## Prisma: Database connections

https://www.prisma.io/docs/orm/prisma-client/setup-and-configuration/databases-connections#optimizing-the-connection-pool

### データベースが許可できる接続数には限りがある

- データベースが同時に処理できる接続数には限りがある
- 各接続はRAMを必要とするため、利用可能なリソースを拡張せずにデータベース接続の上限を単純に増やすことはできない
- DBのスペックを上げることをせずに、DBに対する接続数を増やせば、データベースのパフォーマンスに大きく影響し、メモリ不足エラーのため にデータベースがシャットダウンされる可能性がある
- アプリケーションがDBとの接続を管理する方法は、DBのパフォーマンスに大きく影響する

### Serverless環境でない場合に推奨されるconnection pool size(connection_limit)

長時間稼動するプロセス（e.g. Heroku, VM）用に推奨される接続プール・サイズ（connection_limit）は、default pool size（num_physical_cpus * 2 + 1）÷アプリケーション・インスタンス数

※num_physical_cpusは、アプリケーションが動作しているマシンのCPU数。DBのCPUではないことに注意。

- アプリケーション・インスタンスが1つの場合
  - デフォルトのプール・サイズ（num_physical_cpus * 2 + 1）がデフォルトで適用されるため、connection_limitパラメータを設定する必要はない
  - （必要に応じて）オプションでプール・サイズを調整できる
- 複数のアプリケーション・インスタンスがある場合
  - connection_limitパラメータを手動で設定する必要がある
    - e.g. 例えば、計算されたプール・サイズが10で、アプリケーションのインスタンスが2つある場合、connection_limitパラメータは5以下にする必要がある
  - （必要に応じて）オプションでプール・サイズを調整できる

### PrismaClientを使い回す

長時間稼動するアプリケーションでは、次の設定がおすすめ。

- PrismaClientのインスタンスを1つ作成し、アプリケーション全体で再利用する
- 新しいインスタンスの作成によるホットリロードを防ぐため、`開発環境でのみ`PrismaClientをグローバル変数に割り当てる

### Serverless環境にて推奨される設定

外部接続プーラーの有無に基づいてpool size（connection_limit）を設定し、オプションでプールサイズを調整するのが基本。

1. connection_limitを1に設定することから始める
2. より小さいプールサイズでは十分でない場合は、PgBouncerのような外部接続プーラーの使用を検討する

外部コネクション・プーラーを使用していない場合は、プール・サイズ（connection_limit）を 1 に設定することから始め、その後最適化する。Serverless環境の場合、connection_limit が高いと、トラフィック急増時にデータベース接続制限をすぐに使い果たす可能性がある。（データベースが落ちる可能性）

以下はURL設定の例。

```
mysql://USER:PASSWORD@HOST:PORT/DATABASE?connection_limit=1
```

### Serverless環境における課題

サーバーレス環境では、各関数は独自のPrismaClientインスタンスを作成し、各クライアントインスタンスは独自の接続プールを持つ。

例えば、connection_limitが10の場合、リクエスト数が少なくて一つのインスタンス（PrismaClient）しかなければ、DBに対するコネクション数は10なので特に問題ない。

しかし、大量のアクセスがきてインスタンスがスケールした場合は、それぞれのインスタンスが10のコネクションを持っていると、DBのコネクション制限にヒットして、DBのリソースが枯渇して落ちる可能性がある。

### Prismaにおけるconnection poolの調整

以下に気を付ける。

- DBのconnection limitを使い果たさないようにする
- poolのtimeoutエラーが起こらないようにする（要は、設定したtimeoutの時間内に、クエリがconnection poolから接続を得られていないということなので。詰まっている..）

poolのconnection_limitの数値を上げることで、query engineはより多くのクエリを並行して処理できるようになる。つまり、処理効率が上がる

### その他Serverless環境における考慮事項

- 同時実行数の制限
  - サーバーレスの同時実行制限（並行して実行されるサーバーレス関数の数）によっては、データベースの接続制限を使い果たす可能性がある
  - これは、あまりにも多くの関数が同時に呼び出され、それぞれが独自の接続プールを持っている場合に発生する可能性があり、最終的にデータベースの接続制限を使い果たす
  - これを防ぐには、サーバーレスの同時実行制限を、データベースの最大接続制限を各関数の呼び出しで使用される接続数で割った値よりも低い値に設定する
